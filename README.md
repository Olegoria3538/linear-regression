Регрессия - зависимость среднего значения какой-либо величины от некоторой другой величины или от нескольких величин.

# Постановка задачи линейной регрессии.

Задача регрессии — это задача предсказания одной непрерывной случайной величины на основе значений других случайных величин.

Модель линейной двумерной регрессии имеет вид:
y = a + b*x + ε

Величина переменной y состоит из двух составляющих:
1) неслучайной составляющей y = a + b*x 
2) случайной составляющей (ошибки) ε

На рисунке (Рис. 1) показано,как комбинация этих двух составляющих определяет величину y<sub>i</sub> для случая парной линейной модели регрессии.

<div align="center">
  <img src="https://raw.githubusercontent.com/Olegoria3538/linear-regression/main/images/model.png" />
  <div>Рис. 1</div>
</div>


# Метод наименьших квадратов.

Метод наименьших квадратов один из методов теории ошибок для оценки неизвестных величин по результатам измерений, содержащих случайные ошибки.
Задача заключается в нахождении коэффициентов линейной зависимости, при которых функция двух переменных а и b (Рис. 2) принимает наименьшее значение.
<div align="center">
  <img src="https://raw.githubusercontent.com/Olegoria3538/linear-regression/main/images/mkn.jpg"  />
  <div>Рис. 2</div>
</div>

То есть, при данных а и b сумма квадратов отклонений экспериментальных данных от найденной прямой будет наименьшей. В этом вся суть метода наименьших квадратов.
Таким образом, решение примера сводится к нахождению экстремума функции двух переменных.

Алгебраическое решение (Рис. 3):
<div align="center">
  <img src="https://raw.githubusercontent.com/Olegoria3538/linear-regression/main/images/mnk-algebra.jpg"  />
  <div>Рис. 3</div>
</div>
