Регрессия - зависимость среднего значения какой-либо величины от некоторой другой величины или от нескольких величин.

# Постановка задачи линейной регрессии.

Задача регрессии — это задача предсказания одной непрерывной случайной величины на основе значений других случайных величин.

Модель линейной двумерной регрессии имеет вид:
y = a + b*x + ε

Величина переменной y состоит из двух составляющих:
1) неслучайной составляющей y = a + b*x 
2) случайной составляющей (ошибки) ε

На рисунке (Рис. 1) показано,как комбинация этих двух составляющих определяет величину y<sub>i</sub> для случая парной линейной модели регрессии.

<div align="center">
  <img src="https://raw.githubusercontent.com/Olegoria3538/linear-regression/main/images/model.png" />
  <div>Рис. 1</div>
</div>


# Метод наименьших квадратов.

Метод наименьших квадратов один из методов теории ошибок для оценки неизвестных величин по результатам измерений, содержащих случайные ошибки.
Задача заключается в нахождении коэффициентов линейной зависимости, при которых функция двух переменных а и b (Рис. 2) принимает наименьшее значение.
<div align="center">
  <img src="https://raw.githubusercontent.com/Olegoria3538/linear-regression/main/images/mkn.jpg"  />
  <div>Рис. 2</div>
</div>

То есть, при данных а и b сумма квадратов отклонений экспериментальных данных от найденной прямой будет наименьшей. В этом вся суть метода наименьших квадратов.
Таким образом, решение примера сводится к нахождению экстремума функции двух переменных.

Алгебраическое решение (Рис. 3):
<div align="center">
  <img src="https://raw.githubusercontent.com/Olegoria3538/linear-regression/main/images/mnk-algebra.jpg"  />
  <div>Рис. 3</div>
</div>

# Ковариация, корреляция.
Ковариация — это мера того, как две случайные величины изменятся при сравнении друг с другом. Характеризует степень линейной зависимости двух случайных величин.  
Если ковариация положительна, то с ростом значений одной случайной величины, значения второй имеют тенденцию возрастать, а если знак отрицательный — то убывать.
Однако только по абсолютному значению ковариации нельзя судить о том, насколько сильно величины взаимосвязаны, так как масштаб ковариации зависит от их дисперсий. Ковариацию можно найти по следующей формуле (Рис. 4):
<div align="center">
  <img src="https://raw.githubusercontent.com/Olegoria3538/linear-regression/main/images/cov.jpg"  />
  <div>Рис. 4</div>
</div>

Значение ковариации можно нормировать, поделив её на произведение среднеквадратических отклонений (квадратных корней из дисперсий) случайных величин (Рис. 5). Это будет коэфицент кореляции.
Коэффициент корреляции — это показатель взаимного вероятностного влияния двух случайных величин. Коэффициент корреляции R может принимать значения от -1 до +1.
Если абсолютное значение находится ближе к 1, то это свидетельство сильной связи между величинами, а если ближе к 0 — то, это говорит о слабой связи или ее отсутствии.

<div align="center">
  <img src="https://raw.githubusercontent.com/Olegoria3538/linear-regression/main/images/cor.jpg"  />
  <div>Рис. 5</div>
</div>

